{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e15b8d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c050f8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added c:\\Code\\DL\\bbosis\\Hongyuan-Babesiosis to Python path\n"
     ]
    }
   ],
   "source": [
    "# Add parent directory to Python path for imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the repository root (parent of tests directory)\n",
    "repo_root = Path(__file__).parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "    \n",
    "print(f\"Added {repo_root} to Python path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b95112f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.training.ModelConfig import TrainingConfig\n",
    "from core.training.BagDataset import EmbeddingBagDataset\n",
    "from core.training.trainer import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f12da56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.0281])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Code/DL/bbosis/Hongyuan-Babesiosis/data/training.csv\")\n",
    "y_train = df['label'].values\n",
    "n_pos = (y_train=='BABSP').sum()\n",
    "n_neg = (y_train=='NTTGS').sum()\n",
    "pos_weight = torch.tensor([n_neg / max(1, n_pos)], dtype=torch.float32)\n",
    "pos_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088b244",
   "metadata": {},
   "source": [
    "## Setup Test Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "557c65ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = TrainingConfig(\n",
    "    embeddings_path= Path(r\"C:\\Code\\DL\\bbosis\\Hongyuan-Babesiosis\\data\\embeddings\\embeddings.pt\"),\n",
    "    labels_path= Path(r\"C:\\Code\\DL\\bbosis\\Hongyuan-Babesiosis\\data\\embeddings\\labels.pt\"),\n",
    "    val_embeddings_path= Path(r\"C:\\Code\\DL\\bbosis\\Hongyuan-Babesiosis\\data\\embeddings\\val_embeddings.pt\"),\n",
    "    val_labels_path= Path(r\"C:\\Code\\DL\\bbosis\\Hongyuan-Babesiosis\\data\\embeddings\\val_labels.pt\"),\n",
    "    output_dir= Path(\"runs/training_run_mil_1\"),\n",
    "    epochs=10,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    max_tiles=144,\n",
    "    checkpoint_every=1,\n",
    "    seed=42,\n",
    "    pos_weight=pos_weight.item(),\n",
    "    hidden_dim=1024,\n",
    "    att_dim=1024,\n",
    "    dropout=0.0\n",
    ")\n",
    "config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "104b0a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\DL\\bbosis\\Hongyuan-Babesiosis\\core\\training\\BagDataset.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  raw_entries = torch.load(self.embeddings_path, map_location=\"cpu\")\n",
      "c:\\Code\\DL\\bbosis\\Hongyuan-Babesiosis\\core\\training\\BagDataset.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  labels_tensor = torch.load(labels_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1607"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = EmbeddingBagDataset(\n",
    "    embeddings_path=config.embeddings_path,\n",
    "    labels_path=config.labels_path,\n",
    "    max_tiles=config.max_tiles\n",
    ")\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09739999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 1.2043  accuracy: 0.5513  precision: 0.1432  roc_auc: 0.5952  avg_prec: 0.1653\n",
      "  Val   loss: 0.9752  accuracy: 0.5394  precision: 0.0904  roc_auc: 0.6592  avg_prec: 0.1358\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 1.1491  accuracy: 0.5943  precision: 0.1624  roc_auc: 0.6621  avg_prec: 0.1892\n",
      "  Val   loss: 1.3637  accuracy: 0.1501  precision: 0.0724  roc_auc: 0.6676  avg_prec: 0.1327\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 1.1230  accuracy: 0.5999  precision: 0.1674  roc_auc: 0.6862  avg_prec: 0.2131\n",
      "  Val   loss: 0.9560  accuracy: 0.5751  precision: 0.1023  roc_auc: 0.6630  avg_prec: 0.1379\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 1.1091  accuracy: 0.6335  precision: 0.1834  roc_auc: 0.6999  avg_prec: 0.2180\n",
      "  Val   loss: 1.0082  accuracy: 0.5318  precision: 0.1015  roc_auc: 0.6381  avg_prec: 0.1279\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 1.1218  accuracy: 0.6148  precision: 0.1762  roc_auc: 0.6916  avg_prec: 0.2011\n",
      "  Val   loss: 0.9849  accuracy: 0.5369  precision: 0.1066  roc_auc: 0.6613  avg_prec: 0.1398\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 1.0749  accuracy: 0.6472  precision: 0.1898  roc_auc: 0.7278  avg_prec: 0.2591\n",
      "  Val   loss: 0.9198  accuracy: 0.7354  precision: 0.0947  roc_auc: 0.6697  avg_prec: 0.1339\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 1.0835  accuracy: 0.6316  precision: 0.1892  roc_auc: 0.7255  avg_prec: 0.2496\n",
      "  Val   loss: 1.0328  accuracy: 0.4656  precision: 0.1004  roc_auc: 0.6770  avg_prec: 0.1366\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 1.0656  accuracy: 0.6503  precision: 0.2028  roc_auc: 0.7376  avg_prec: 0.2372\n",
      "  Val   loss: 0.9989  accuracy: 0.5140  precision: 0.1019  roc_auc: 0.6848  avg_prec: 0.1422\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 1.0320  accuracy: 0.6708  precision: 0.2146  roc_auc: 0.7615  avg_prec: 0.2688\n",
      "  Val   loss: 0.9203  accuracy: 0.7786  precision: 0.1250  roc_auc: 0.6900  avg_prec: 0.1483\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train loss: 1.0462  accuracy: 0.6559  precision: 0.2075  roc_auc: 0.7480  avg_prec: 0.2527\n",
      "  Val   loss: 0.9715  accuracy: 0.6819  precision: 0.1048  roc_auc: 0.6488  avg_prec: 0.1271\n",
      "Best checkpoint based on ROC-AUC stored in runs\\training_run_mil_1\\epoch_010\n",
      "Training history written to runs\\training_run_mil_1\\training_history.json\n"
     ]
    }
   ],
   "source": [
    "train(config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
